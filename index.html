<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ASL Translator</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: 'Morva', serif;
      background-color: #000;
      color: white;
      padding-top: 10px;
      min-height: 100vh;
      transition: background 0.3s, color 0.3s;
    }
    body.light {
      background-color: #f0f0f0;
      color: black;
    }
    #video, #canvas {
      position: absolute;
      top: 70px;
      left: 50%;
      transform: translateX(-50%);
      max-width: 640px;
      width: 90%;
      height: auto;
      z-index: 10;
    }
    #controls {
      position: fixed;
      top: 10px;
      left: 10px;
      display: flex;
      flex-direction: column;
      gap: 6px;
      padding: 10px;
      background-color: rgba(0, 0, 0, 0.6);
      border-radius: 10px;
      z-index: 11;
      max-height: 90vh;
      overflow-y: auto;
    }
    #controls button, #cameraSelect {
      padding: 10px;
      font-size: 1em;
      border-radius: 8px;
      background-color: #444;
      color: white;
      cursor: pointer;
      border: none;
    }
    #controls button:hover, #cameraSelect:hover {
      background-color: #666;
    }
    #output {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(34, 34, 34, 0.9);
      padding: 10px 20px;
      border-radius: 10px;
      z-index: 10;
    }
    #loading {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 1.5em;
      color: yellow;
    }
    #topPredictions {
      position: fixed;
      bottom: 10px;
      right: 10px;
      background: rgba(0,0,0,0.7);
      color: white;
      padding: 10px;
      border-radius: 10px;
      font-size: 0.9em;
      max-width: 180px;
    }

    @media (max-width: 768px) {
      #controls {
        flex-direction: row;
        flex-wrap: wrap;
        position: static;
        background: transparent;
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        margin: 5px 0;
        padding: 5px;
      }

      #controls select,
      #controls button {
        flex: 1 1 45%;
        margin: 5px;
      }

      #canvas {
        width: 100%;
        height: auto;
      }
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <div id="controls">
    <h2>ASL Translator</h2>
    <input type="file" id="fileLoader" accept="application/json" />
    <input type="text" id="labelInput" placeholder="Label (e.g., asl_a)" />
    <button onclick="trainGesture()">Train üì∏</button>
    <button onclick="startAutoTrain(100)">Auto Train 100 ‚è≥</button>
    <button onclick="exportTrainingData()">üìÑ Export</button>
    <button onclick="downloadData()">üìÇ Download</button>
    <select id="cameraSelect" onchange="switchCamera()"></select>
    <button onclick="flipCamera()">üîÑ Flip Camera</button>
    <button onclick="speakSentence()">üîä Speak</button>
    <button onclick="backspace()">‚¨ÖÔ∏è Backspace</button>
    <button onclick="clearSentence()">‚ùå Clear</button>
    <button onclick="addSpace()">‚ê£ Space</button>
    <button onclick="toggleTheme()">üåô/‚òÄÔ∏è Theme</button>
  </div>

  <div id="output">
    <p><strong>Prediction:</strong> <span id="prediction">-</span></p>
    <p><strong>Sentence:</strong> <span id="sentence"></span></p>
  </div>

  <div id="topPredictions">
    <strong>Top 3 Predictions</strong>
    <ul id="top3List"></ul>
  </div>

  <div id="loading">Loading ASL model data...</div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>

  <script>
    const canvasElement = document.getElementById("canvas");
    const videoElement = document.getElementById("video");
    const canvasCtx = canvasElement.getContext("2d");

    let trainingData = {}, currentLandmarks = null, lastPrediction = '', lastAddTime = 0;
    let currentSentence = localStorage.getItem("savedSentence") || '';
    const top3List = document.getElementById("top3List");
    const predictionEl = document.getElementById("prediction");
    const sentenceEl = document.getElementById("sentence");
    sentenceEl.textContent = currentSentence;

    const hands = new Hands({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}` });
    hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.8, minTrackingConfidence: 0.5 });

    const HAND_CONNECTIONS = [
      [0, 1], [1, 2], [2, 3], [3, 4], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12],
      [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 19], [19, 20]
    ];

    hands.onResults(results => {
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      if (results.multiHandLandmarks?.length) {
        const landmarks = results.multiHandLandmarks[0];
        currentLandmarks = landmarks;

        // Set canvas dimensions based on video size
        canvasElement.width = videoElement.videoWidth;
        canvasElement.height = videoElement.videoHeight;

        // Scaling landmarks based on video resolution
        const scaleX = canvasElement.width / videoElement.videoWidth;
        const scaleY = canvasElement.height / videoElement.videoHeight;
        const scaledLandmarks = landmarks.map(landmark => ({
          x: landmark.x * videoElement.videoWidth * scaleX,
          y: landmark.y * videoElement.videoHeight * scaleY,
          z: landmark.z
        }));

        // Draw connectors and landmarks on the canvas
        drawConnectors(canvasCtx, scaledLandmarks, HAND_CONNECTIONS, { color: '#0f0' });
        drawLandmarks(canvasCtx, scaledLandmarks, { color: '#0f0', radius: 3 });

        // Normalize landmarks for gesture recognition
        const input = normalizeLandmarks(scaledLandmarks);
        const scores = {};
        for (const label in trainingData) {
          let maxSim = -1;
          for (const sample of trainingData[label]) {
            const sim = cosineSimilarity(input, sample);
            if (sim > maxSim) maxSim = sim;
          }
          scores[label] = maxSim;
        }

        hands.onResults(results => {
          if (results.multiHandLandmarks?.length > 0) {
          const landmarks = results.multiHandLandmarks[0];  // Assuming we're detecting only one hand

    // Clear previous frame
          canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

    // Draw hand landmarks and connections
          drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: '#0f0' });
          drawLandmarks(canvasCtx, landmarks, { color: '#0f0', radius: 3 });

    // Optionally, normalize and compare landmarks for gesture recognition here
        }
      });


        // Display top 3 predictions
        const sorted = Object.entries(scores).sort((a, b) => b[1] - a[1]);
        top3List.innerHTML = sorted.slice(0, 3).map(([l, s]) => `<li>${l} (${(s * 100).toFixed(1)}%)</li>`).join('');
        if (!sorted.length) {
          top3List.innerHTML = '<li>No predictions</li>';
        }

        if (sorted.length && sorted[0][1] > 0.975) {
          const [pred] = sorted[0];
          predictionEl.textContent = `${pred} (${(sorted[0][1] * 100).toFixed(1)}%)`;
          const now = Date.now();
          if (pred !== lastPrediction || now - lastAddTime > 1000) {
            currentSentence += pred.replace("asl_", "").toUpperCase();
            sentenceEl.textContent = currentSentence;
            localStorage.setItem("savedSentence", currentSentence);
            lastPrediction = pred;
            lastAddTime = now;
          }
        } else {
          predictionEl.textContent = "-";
          lastPrediction = '';
        }
      }
    });

    async function listCameras() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const cameraSelect = document.getElementById("cameraSelect");
      cameraSelect.innerHTML = '';
      const allCameras = devices.filter(d => d.kind === "videoinput");
      allCameras.forEach((device, i) => {
        const option = document.createElement("option");
        option.value = device.deviceId;
        option.textContent = device.label || `Camera ${i + 1}`;
        cameraSelect.appendChild(option);
      });
      if (allCameras.length) startCamera(allCameras[0].deviceId);
    }

    function switchCamera() {
      const selectedId = document.getElementById("cameraSelect").value;
      startCamera(selectedId);
    }

    function flipCamera() {
      const currentCameraIndex = document.getElementById("cameraSelect").selectedIndex;
      const allCameras = document.getElementById("cameraSelect").options;
      const newIndex = (currentCameraIndex + 1) % allCameras.length;
      startCamera(allCameras[newIndex].value);
    }

    function startCamera(deviceId) {
      navigator.mediaDevices.getUserMedia({ video: { deviceId: { exact: deviceId } } })
        .then(stream => {
          videoElement.srcObject = stream;
          const loop = async () => {
            if (videoElement.readyState >= 2) await hands.send({ image: videoElement });
            requestAnimationFrame(loop);
          };
          loop();
        })
        .catch(err => {
          alert("Camera access failed. Please allow permission.");
          console.error(err);
        });
    }

    // Load training data
    fetch("asl_data.json")
      .then(res => res.json())
      .then(data => {
        trainingData = data;
        document.getElementById("loading").style.display = "none";
      })
      .catch(err => {
        document.getElementById("loading").textContent = "‚ùå Failed to load model data";
      });

    function normalizeLandmarks(landmarks) {
      const base = landmarks[0];
      return landmarks.flatMap(pt => [pt.x - base.x, pt.y - base.y, pt.z - base.z]);
    }

    function cosineSimilarity(a, b) {
      let dot = 0, aMag = 0, bMag = 0;
      for (let i = 0; i < a.length; i++) {
        dot += a[i] * b[i]; aMag += a[i] * a[i]; bMag += b[i] * b[i];
      }
      return dot / (Math.sqrt(aMag) * Math.sqrt(bMag));
    }

    function trainGesture() {
      const label = document.getElementById("labelInput").value.trim().toLowerCase();
      if (!label || !currentLandmarks) return alert("Enter label and show hand.");
      const key = label.startsWith("asl_") ? label : "asl_" + label;
      const norm = normalizeLandmarks(currentLandmarks);
      if (!trainingData[key]) trainingData[key] = [];
      trainingData[key].push(norm);
      alert(`‚úÖ Trained ${key}`);
    }

    function startAutoTrain(n = 100) {
      const label = document.getElementById("labelInput").value.trim().toLowerCase();
      if (!label) return alert("Enter label.");
      const key = label.startsWith("asl_") ? label : "asl_" + label;
      let i = 0;
      const interval = setInterval(() => {
        if (!currentLandmarks) return;
        const norm = normalizeLandmarks(currentLandmarks);
        if (!trainingData[key]) trainingData[key] = [];
        trainingData[key].push(norm);
        if (++i >= n) clearInterval(interval);
      }, 200);
    }

    function speakSentence() {
      const utter = new SpeechSynthesisUtterance(currentSentence);
      speechSynthesis.speak(utter);
    }

    function backspace() {
      currentSentence = currentSentence.slice(0, -1);
      sentenceEl.textContent = currentSentence;
    }

    function clearSentence() {
      currentSentence = '';
      sentenceEl.textContent = '';
    }

    function addSpace() {
      currentSentence += ' ';
      sentenceEl.textContent = currentSentence;
    }

    function toggleTheme() {
      document.body.classList.toggle("light");
    }

    function exportTrainingData() {
      const blob = new Blob([JSON.stringify(trainingData)], { type: "application/json" });
      const a = document.createElement("a");
      a.href = URL.createObjectURL(blob);
      a.download = "asl_data.json";
      a.click();
    }

    function downloadData() {
      exportTrainingData();
    }

    document.getElementById("fileLoader").addEventListener("change", e => {
      const file = e.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        trainingData = JSON.parse(reader.result);
        alert("‚úÖ Data loaded!");
      };
      reader.readAsText(file);
    });

    window.addEventListener("keydown", e => {
      if (e.key === 'Backspace') backspace();
      if (e.key === ' ') { e.preventDefault(); addSpace(); }
      if (e.key === 'Escape') clearSentence();
    });

    window.addEventListener("beforeunload", () => {
      localStorage.setItem("savedSentence", currentSentence);
    });

    window.addEventListener("DOMContentLoaded", listCameras);
  </script>
</body>
</html>
