<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ğŸ¾ ASL Translator with MediaPipe ğŸ¾</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: 'Arial', sans-serif;
      background-color: #000;
      color: #fff;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    video {
      width: 100%;
      height: auto;
    }
  </style>
</head>
<body>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" width="640" height="480"></canvas>

  <!-- Add MediaPipe and TensorFlow scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1630138465/mediapipe_hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.0.0"></script>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('canvas');
    const canvasCtx = canvasElement.getContext('2d');

    // Set up the webcam video stream
    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true
      });
      videoElement.srcObject = stream;
    }

    // MediaPipe Hands setup
    const hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1630138465/${file}`
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    // Callback when landmarks are detected
    hands.onResults((results) => {
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      
      // Draw the hand landmarks
      if (results.multiHandLandmarks) {
        results.multiHandLandmarks.forEach((landmarks) => {
          drawLandmarks(canvasCtx, landmarks);
        });
      }
    });

    // Draw the landmarks
    function drawLandmarks(ctx, landmarks) {
      for (let i = 0; i < landmarks.length; i++) {
        const x = landmarks[i].x * canvasElement.width;
        const y = landmarks[i].y * canvasElement.height;
        ctx.beginPath();
        ctx.arc(x, y, 5, 0, 2 * Math.PI);
        ctx.fillStyle = 'red';
        ctx.fill();
      }
    }

    // Start the camera and hands detection
    setupCamera().then(() => {
      videoElement.onloadeddata = () => {
        hands.send({ image: videoElement });
      };
    });

    // Continuously detect the hands
    videoElement.addEventListener('play', () => {
      function detect() {
        hands.send({ image: videoElement });
        requestAnimationFrame(detect);
      }
      detect();
    });
  </script>
</body>
</html>
