
Conversation with Gemini
<!DOCTYPE html>

<html lang="en">

<head>

Â  <meta charset="UTF-8" />

Â  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

Â  <title>ğŸˆ ASL Translator ğŸˆ</title>

Â  <style>

Â  Â  * { box-sizing: border-box; margin: 0; padding: 0; }

Â  Â  body {

Â  Â  Â  font-family: 'Arial', sans-serif;

Â  Â  Â  background-color: #000;

Â  Â  Â  color: white;

Â  Â  Â  padding-top: 10px;

Â  Â  Â  min-height: 100vh;

Â  Â  Â  transition: background 0.3s, color 0.3s;

Â  Â  }

Â  Â  body.light {

Â  Â  Â  background-color: #f0f0f0;

Â  Â  Â  color: black;

Â  Â  }

Â  Â  #video, #canvas {

Â  Â  Â  position: absolute;

Â  Â  Â  top: 70px;

Â  Â  Â  left: 50%;

Â  Â  Â  transform: translateX(-50%);

Â  Â  Â  width: 100%;

Â  Â  Â  max-width: 640px;

Â  Â  Â  height: auto;

Â  Â  }

Â  Â  #controls {

Â  Â  Â  position: fixed;

Â  Â  Â  top: 10px;

Â  Â  Â  left: 10px;

Â  Â  Â  display: flex;

Â  Â  Â  flex-direction: column;

Â  Â  Â  gap: 6px;

Â  Â  Â  padding: 10px;

Â  Â  Â  background-color: rgba(0, 0, 0, 0.6);

Â  Â  Â  border-radius: 10px;

Â  Â  Â  z-index: 11;

Â  Â  Â  max-height: 90vh;

Â  Â  Â  overflow-y: auto;

Â  Â  }

Â  Â  #controls button, #spaceButton, #cameraSelect {

Â  Â  Â  padding: 10px;

Â  Â  Â  font-size: 1em;

Â  Â  Â  border-radius: 8px;

Â  Â  Â  background-color: #444;

Â  Â  Â  color: white;

Â  Â  Â  cursor: pointer;

Â  Â  Â  border: none;

Â  Â  }

Â  Â  #controls button:hover, #spaceButton:hover, #cameraSelect:hover {

Â  Â  Â  background-color: #666;

Â  Â  }

Â  Â  #output {

Â  Â  Â  position: absolute;

Â  Â  Â  bottom: 10px;

Â  Â  Â  left: 50%;

Â  Â  Â  transform: translateX(-50%);

Â  Â  Â  background: rgba(34, 34, 34, 0.9);

Â  Â  Â  padding: 10px 20px;

Â  Â  Â  border-radius: 10px;

Â  Â  Â  z-index: 10;

Â  Â  }

Â  Â  #loading {

Â  Â  Â  position: fixed;

Â  Â  Â  top: 50%;

Â  Â  Â  left: 50%;

Â  Â  Â  transform: translate(-50%, -50%);

Â  Â  Â  font-size: 1.5em;

Â  Â  Â  color: yellow;

Â  Â  }

Â  Â  #topPredictions {

Â  Â  Â  position: fixed;

Â  Â  Â  bottom: 10px;

Â  Â  Â  right: 10px;

Â  Â  Â  background: rgba(0,0,0,0.7);

Â  Â  Â  color: white;

Â  Â  Â  padding: 10px;

Â  Â  Â  border-radius: 10px;

Â  Â  Â  font-size: 0.9em;

Â  Â  Â  max-width: 180px;

Â  Â  }

Â  Â  #top3List {

Â  Â  Â  list-style: none;

Â  Â  Â  padding-left: 0;

Â  Â  Â  margin: 5px 0 0 0;

Â  Â  }

Â  </style>

</head>

<body>

Â  <video id="video" autoplay playsinline></video>

Â  <canvas id="canvas"></canvas>



Â  <div id="controls">

Â  Â  <h2>ğŸˆ ASL Translator</h2>

Â  Â  <input type="file" id="fileLoader" accept="application/json" />

Â  Â  <input type="text" id="labelInput" placeholder="Label (e.g., asl_a)" />

Â  Â  <button onclick="trainGesture()">Train ğŸ“¸</button>

Â  Â  <button onclick="startAutoTrain(100)">Auto Train 100 â³</button>

Â  Â  <button onclick="exportTrainingData()">ğŸ“„ Export</button>

Â  Â  <button onclick="downloadData()">ğŸ“‚ Download</button>

Â  Â  <select id="cameraSelect" onchange="switchCamera()"></select>

Â  Â  <button onclick="flipCamera()">ğŸ”„ Flip Camera</button>

Â  Â  <button onclick="speakSentence()">ğŸ”Š Speak</button>

Â  Â  <button onclick="backspace()">â¬…ï¸ Backspace</button>

Â  Â  <button onclick="clearSentence()">âŒ Clear</button>

Â  Â  <button onclick="addSpace()">â£ Space</button>

Â  Â  <button onclick="toggleTheme()">ğŸŒ™/â˜€ï¸ Theme</button>

Â  </div>



Â  <div id="output">

Â  Â  <p><strong>Prediction:</strong> <span id="prediction">-</span></p>

Â  Â  <p><strong>Sentence:</strong> <span id="sentence"></span></p>

Â  </div>



Â  <div id="topPredictions">

Â  Â  <strong>Top 3 Predictions</strong>

Â  Â  <ul id="top3List"></ul>

Â  </div>



Â  <div id="loading">Loading ASL model data...</div>



Â  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>

Â  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>



Â  <script>

Â  Â  const canvasElement = document.getElementById("canvas");

Â  Â  const videoElement = document.getElementById("video");

Â  Â  const canvasCtx = canvasElement.getContext("2d");



Â  Â  let trainingData = {}, currentLandmarks = null, lastPrediction = '', lastAddTime = 0;

Â  Â  let currentSentence = localStorage.getItem("savedSentence") || '';

Â  Â  const top3List = document.getElementById("top3List");

Â  Â  const predictionEl = document.getElementById("prediction");

Â  Â  const sentenceEl = document.getElementById("sentence");

Â  Â  sentenceEl.textContent = currentSentence;



Â  Â  let allCameras = [], currentCameraIndex = 0, currentStream = null;



Â  Â  const hands = new Hands({ locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}` });

Â  Â  hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.8, minTrackingConfidence: 0.5 });



Â  Â  async function listCameras() {

Â  Â  Â  const devices = await navigator.mediaDevices.enumerateDevices();

Â  Â  Â  const cameraSelect = document.getElementById("cameraSelect");

Â  Â  Â  cameraSelect.innerHTML = '';

Â  Â  Â  allCameras = devices.filter(d => d.kind === "videoinput");

Â  Â  Â  allCameras.forEach((device, i) => {

Â  Â  Â  Â  const option = document.createElement("option");

Â  Â  Â  Â  option.value = device.deviceId;

Â  Â  Â  Â  option.textContent = device.label || `Camera ${i + 1}`;

Â  Â  Â  Â  cameraSelect.appendChild(option);

Â  Â  Â  });

Â  Â  Â  if (allCameras.length) startCamera(allCameras[0].deviceId);

Â  Â  }



Â  Â  function switchCamera() {

Â  Â  Â  const selectedId = document.getElementById("cameraSelect").value;

Â  Â  Â  currentCameraIndex = allCameras.findIndex(c => c.deviceId === selectedId);

Â  Â  Â  startCamera(selectedId);

Â  Â  }



Â  Â  function flipCamera() {

Â  Â  Â  currentCameraIndex = (currentCameraIndex + 1) % allCameras.length;

Â  Â  Â  const deviceId = allCameras[currentCameraIndex].deviceId;

Â  Â  Â  document.getElementById("cameraSelect").selectedIndex = currentCameraIndex;

Â  Â  Â  startCamera(deviceId);

Â  Â  }



Â  Â  function startCamera(deviceId) {

Â  Â  Â  if (currentStream) currentStream.getTracks().forEach(track => track.stop());

Â  Â  Â  navigator.mediaDevices.getUserMedia({ video: { deviceId: { exact: deviceId } } })

Â  Â  Â  Â  .then(stream => {

Â  Â  Â  Â  Â  currentStream = stream;

Â  Â  Â  Â  Â  videoElement.srcObject = stream;



Â  Â  Â  Â  Â  const loop = async () => {

Â  Â  Â  Â  Â  Â  if (videoElement.readyState >= 2) await hands.send({ image: videoElement });

Â  Â  Â  Â  Â  Â  requestAnimationFrame(loop);

Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  loop();

Â  Â  Â  Â  })

Â  Â  Â  Â  .catch(err => {

Â  Â  Â  Â  Â  alert("Camera access failed. Please allow permission.");

Â  Â  Â  Â  Â  console.error(err);

Â  Â  Â  Â  });

Â  Â  }



Â  Â  function resizeCanvas() {

Â  Â  Â  canvasElement.width = videoElement.videoWidth;

Â  Â  Â  canvasElement.height = videoElement.videoHeight;

Â  Â  }



Â  Â  videoElement.onloadedmetadata = () => {

Â  Â  Â  resizeCanvas();

Â  Â  Â  const loop = async () => {

Â  Â  Â  Â  if (videoElement.readyState >= 2) await hands.send({ image: videoElement });

Â  Â  Â  Â  requestAnimationFrame(loop);

Â  Â  Â  };

Â  Â  Â  loop();

Â  Â  };



Â  Â  fetch("asl_data.json").then(res => res.json()).then(data => {

Â  Â  Â  trainingData = data;

Â  Â  Â  document.getElementById("loading").style.display = "none";

Â  Â  }).catch(err => {

Â  Â  Â  document.getElementById("loading").textContent = "âŒ Failed to load model data";

Â  Â  });



Â  Â  hands.onResults(results => {

Â  Â  Â  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

Â  Â  Â  if (results.multiHandLandmarks?.length) {

Â  Â  Â  Â  const landmarks = results.multiHandLandmarks[0];

Â  Â  Â  Â  currentLandmarks = landmarks;



Â  Â  Â  Â  // Adjust the landmarks position based on the canvas size and video element size

Â  Â  Â  Â  const adjustedLandmarks = landmarks.map(pt => ({

Â  Â  Â  Â  Â  x: pt.x * canvasElement.width,

Â  Â  Â  Â  Â  y: pt.y * canvasElement.height,

Â  Â  Â  Â  }));



Â  Â  Â  Â  // Draw the connectors and landmarks with adjusted coordinates

Â  Â  Â  Â  drawConnectors(canvasCtx, adjustedLandmarks, HAND_CONNECTIONS, { color: '#0f0' });

Â  Â  Â  Â  drawLandmarks(canvasCtx, adjustedLandmarks, { color: '#0f0', radius: 3 });



Â  Â  Â  Â  const input = normalizeLandmarks(adjustedLandmarks);

Â  Â  Â  Â  const scores = {};

Â  Â  Â  Â  for (const label in trainingData) {

Â  Â  Â  Â  Â  let maxSim = -1;

Â  Â  Â  Â  Â  for (const sample of trainingData[label]) {

Â  Â  Â  Â  Â  Â  const sim = cosineSimilarity(input, sample);

Â  Â  Â  Â  Â  Â  if (sim > maxSim) maxSim = sim;

Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  scores[label] = maxSim;

Â  Â  Â  Â  }



Â  Â  Â  Â  const sorted = Object.entries(scores).sort((a, b) => b[1] - a[1]);

Â  Â  Â  Â  top3List.innerHTML = sorted.slice(0, 3).map(([l, s]) => `<li>${l} (${(s*100).toFixed(1)}%)</li>`).join('');

Â  Â  Â  Â  if (sorted.length && sorted[0][1] > 0.95) {

Â  Â  Â  Â  Â  const [pred] = sorted[0];

Â  Â  Â  Â  Â  predictionEl.textContent = `${pred} (${(sorted[0][1] * 100).toFixed(1)}%)`;

Â  Â  Â  Â  Â  const now = Date.now();

Â  Â  Â  Â  Â  if (pred !== lastPrediction || now - lastAddTime > 1000) {

Â  Â  Â  Â  Â  Â  currentSentence += pred.replace("asl_", "").toUpperCase();

Â  Â  Â  Â  Â  Â  sentenceEl.textContent = currentSentence;

Â  Â  Â  Â  Â  Â  localStorage.setItem("savedSentence", currentSentence);

Â  Â  Â  Â  Â  Â  lastPrediction = pred;

Â  Â  Â  Â  Â  Â  lastAddTime = now;

Â  Â  Â  Â  Â  }

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  predictionEl.textContent = "-";

Â  Â  Â  Â  Â  lastPrediction = '';

Â  Â  Â  Â  }

Â  Â  Â  }

Â  Â  });



Â  Â  function normalizeLandmarks(landmarks) {

Â  Â  Â  const base = landmarks[0];

Â  Â  Â  return landmarks.flatMap(pt => [pt.x - base.x, pt.y - base.y, pt.z - base.z]);

Â  Â  }



Â  Â  function cosineSimilarity(a, b) {

Â  Â  Â  let dot = 0, aMag = 0, bMag = 0;

Â  Â  Â  for (let i = 0; i < a.length; i++) {

Â  Â  Â  Â  dot += a[i] * b[i]; aMag += a[i] * a[i]; bMag += b[i] * b[i];

Â  Â  Â  }

Â  Â  Â  return dot / (Math.sqrt(aMag) * Math.sqrt(bMag));

Â  Â  }



Â  Â  function trainGesture() {

Â  Â  Â  const label = document.getElementById("labelInput").value.trim().toLowerCase();

Â  Â  Â  if (!label || !currentLandmarks) return alert("Enter label and show hand.");

Â  Â  Â  const key = label.startsWith("asl_") ? label : "asl_" + label;

Â  Â  Â  const norm = normalizeLandmarks(currentLandmarks);

Â  Â  Â  if (!trainingData[key]) trainingData[key] = [];

Â  Â  Â  trainingData[key].push(norm);

Â  Â  Â  alert(`âœ… Trained ${key}`);

Â  Â  }



Â  Â  function startAutoTrain(n = 100) {

Â  Â  Â  const label = document.getElementById("labelInput").value.trim().toLowerCase();

Â  Â  Â  if (!label) return alert("Enter label.");

Â  Â  Â  const key = label.startsWith("asl_") ? label : "asl_" + label;

Â  Â  Â  let i = 0;

Â  Â  Â  const interval = setInterval(() => {

Â  Â  Â  Â  if (!currentLandmarks) return;

Â  Â  Â  Â  const norm = normalizeLandmarks(currentLandmarks);

Â  Â  Â  Â  if (!trainingData[key]) trainingData[key] = [];

Â  Â  Â  Â  trainingData[key].push(norm);

Â  Â  Â  Â  if (++i >= n) clearInterval(interval);

Â  Â  Â  }, 200);

Â  Â  }



Â  Â  function speakSentence() {

Â  Â  Â  const utter = new SpeechSynthesisUtterance(currentSentence);

Â  Â  Â  speechSynthesis.speak(utter);

Â  Â  }



Â  Â  function backspace() {

Â  Â  Â  currentSentence = currentSentence.slice(0, -1);

Â  Â  Â  sentenceEl.textContent = currentSentence;

Â  Â  }



Â  Â  function clearSentence() {

Â  Â  Â  currentSentence = '';

Â  Â  Â  sentenceEl.textContent = '';

Â  Â  }



Â  Â  function addSpace() {

Â  Â  Â  currentSentence += ' ';

Â  Â  Â  sentenceEl.textContent = currentSentence;

Â  Â  }



Â  Â  function toggleTheme() {

Â  Â  Â  document.body.classList.toggle("light");

Â  Â  }



Â  Â  function exportTrainingData() {

Â  Â  Â  const blob = new Blob([JSON.stringify(trainingData)], { type: "application/json" });

Â  Â  Â  const a = document.createElement("a");

Â  Â  Â  a.href = URL.createObjectURL(blob);

Â  Â  Â  a.download = "asl_data.json";

Â  Â  Â  a.click();

Â  Â  }



Â  Â  function downloadData() {

Â  Â  Â  exportTrainingData();

Â  Â  }



Â  Â  document.getElementById("fileLoader").addEventListener("change", e => {

Â  Â  Â  const file = e.target.files[0];

Â  Â  Â  if (!file) return;

Â  Â  Â  const reader = new FileReader();

Â  Â  Â  reader.onload = () => {

Â  Â  Â  Â  trainingData = JSON.parse(reader.result);

Â  Â  Â  Â  alert("âœ… Data loaded!");

Â  Â  Â  };

Â  Â  Â  reader.readAsText(file);

Â  Â  });



Â  Â  window.addEventListener("keydown", e => {

Â  Â  Â  if (e.key === 'Backspace') backspace();

Â  Â  Â  if (e.key === ' ') { e.preventDefault(); addSpace(); }

Â  Â  Â  if (e.key === 'Escape') clearSentence();

Â  Â  });



Â  Â  window.addEventListener("beforeunload", () => {

Â  Â  Â  localStorage.setItem("savedSentence", currentSentence);

Â  Â  });



Â  Â  window.addEventListener("DOMContentLoaded", listCameras);

Â  </script>

</body>

</html>
